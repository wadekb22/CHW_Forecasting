{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wade\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (41,42,49,51,89) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv(\"weather.csv\")\n",
    "power = pd.read_csv(\"cleaned_power.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all dates to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "power[\"DATE\"] = power.apply(lambda x: pd.Timestamp(x[\"Timestamp\"]), axis=1)\n",
    "weather[\"DATE\"] = weather.apply(lambda x: pd.Timestamp(x[\"DATE\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure total power is included, reduce to match weather interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim power to match date range\n",
    "date_mismatch = False\n",
    "if date_mismatch:\n",
    "    cutoff = power.index[power['DATE'] == pd.Timestamp('3/1/2020 0:00')].tolist()\n",
    "    power = power.iloc[:cutoff+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total power column\n",
    "if \"Total Power\" not in power.columns:\n",
    "    power[\"Total Power\"] = power.apply(lambda x: sum(x[1:10]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Chiller-2 Power</th>\n",
       "      <th>Chiller-3 Power</th>\n",
       "      <th>Chiller-4 Power</th>\n",
       "      <th>Chiller-5 Power</th>\n",
       "      <th>Chiller-6 Power</th>\n",
       "      <th>Chiller-7 Power</th>\n",
       "      <th>Chiller-8 Power</th>\n",
       "      <th>Chiller-9 Power</th>\n",
       "      <th>Chiller-10 Power</th>\n",
       "      <th>Free Cooling HX Power</th>\n",
       "      <th>DATE</th>\n",
       "      <th>Total Power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/1/2019 0:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/1/2019 0:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-01 00:01:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2019 0:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-01 00:02:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/1/2019 0:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-01 00:03:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/1/2019 0:04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-01 00:04:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052637</th>\n",
       "      <td>2/28/2021 23:56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1367.581299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.628296</td>\n",
       "      <td>2021-02-28 23:56:00</td>\n",
       "      <td>1367.581299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052638</th>\n",
       "      <td>2/28/2021 23:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1352.855835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.884766</td>\n",
       "      <td>2021-02-28 23:57:00</td>\n",
       "      <td>1352.855835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052639</th>\n",
       "      <td>2/28/2021 23:58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1352.390137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492.000519</td>\n",
       "      <td>2021-02-28 23:58:00</td>\n",
       "      <td>1352.390137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052640</th>\n",
       "      <td>2/28/2021 23:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1386.171753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.798767</td>\n",
       "      <td>2021-02-28 23:59:00</td>\n",
       "      <td>1386.171753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052641</th>\n",
       "      <td>3/1/2021 0:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1388.031372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.885406</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>1388.031372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052642 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  Chiller-2 Power  Chiller-3 Power  Chiller-4 Power  \\\n",
       "0          3/1/2019 0:00              0.0         0.000000              0.0   \n",
       "1          3/1/2019 0:01              0.0         0.000000              0.0   \n",
       "2          3/1/2019 0:02              0.0         0.000000              0.0   \n",
       "3          3/1/2019 0:03              0.0         0.000000              0.0   \n",
       "4          3/1/2019 0:04              0.0         0.000000              0.0   \n",
       "...                  ...              ...              ...              ...   \n",
       "1052637  2/28/2021 23:56              0.0      1367.581299              0.0   \n",
       "1052638  2/28/2021 23:57              0.0      1352.855835              0.0   \n",
       "1052639  2/28/2021 23:58              0.0      1352.390137              0.0   \n",
       "1052640  2/28/2021 23:59              0.0      1386.171753              0.0   \n",
       "1052641    3/1/2021 0:00              0.0      1388.031372              0.0   \n",
       "\n",
       "         Chiller-5 Power  Chiller-6 Power  Chiller-7 Power  Chiller-8 Power  \\\n",
       "0                    0.0              0.0              0.0              0.0   \n",
       "1                    0.0              0.0              0.0              0.0   \n",
       "2                    0.0              0.0              0.0              0.0   \n",
       "3                    0.0              0.0              0.0              0.0   \n",
       "4                    0.0              0.0              0.0              0.0   \n",
       "...                  ...              ...              ...              ...   \n",
       "1052637              0.0              0.0              0.0              0.0   \n",
       "1052638              0.0              0.0              0.0              0.0   \n",
       "1052639              0.0              0.0              0.0              0.0   \n",
       "1052640              0.0              0.0              0.0              0.0   \n",
       "1052641              0.0              0.0              0.0              0.0   \n",
       "\n",
       "         Chiller-9 Power  Chiller-10 Power  Free Cooling HX Power  \\\n",
       "0                    0.0               0.0               0.000000   \n",
       "1                    0.0               0.0               0.000000   \n",
       "2                    0.0               0.0               0.000000   \n",
       "3                    0.0               0.0               0.000000   \n",
       "4                    0.0               0.0               0.000000   \n",
       "...                  ...               ...                    ...   \n",
       "1052637              0.0               0.0             486.628296   \n",
       "1052638              0.0               0.0             501.884766   \n",
       "1052639              0.0               0.0             492.000519   \n",
       "1052640              0.0               0.0             500.798767   \n",
       "1052641              0.0               0.0             502.885406   \n",
       "\n",
       "                       DATE  Total Power  \n",
       "0       2019-03-01 00:00:00     0.000000  \n",
       "1       2019-03-01 00:01:00     0.000000  \n",
       "2       2019-03-01 00:02:00     0.000000  \n",
       "3       2019-03-01 00:03:00     0.000000  \n",
       "4       2019-03-01 00:04:00     0.000000  \n",
       "...                     ...          ...  \n",
       "1052637 2021-02-28 23:56:00  1367.581299  \n",
       "1052638 2021-02-28 23:57:00  1352.855835  \n",
       "1052639 2021-02-28 23:58:00  1352.390137  \n",
       "1052640 2021-02-28 23:59:00  1386.171753  \n",
       "1052641 2021-03-01 00:00:00  1388.031372  \n",
       "\n",
       "[1052642 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extraneous columns\n",
    "\n",
    "Only these kept columns do refer to hourly information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[[\"DATE\",\"HourlyAltimeterSetting\",\"HourlyDewPointTemperature\",\"HourlyDryBulbTemperature\",\"HourlyPrecipitation\",\"HourlyPresentWeatherType\",\"HourlyPressureChange\",\"HourlyPressureTendency\",\"HourlyRelativeHumidity\",\"HourlySeaLevelPressure\",\"HourlySkyConditions\",\"HourlyStationPressure\",\"HourlyVisibility\",\"HourlyWetBulbTemperature\",\"HourlyWindDirection\",\"HourlyWindGustSpeed\",\"HourlyWindSpeed\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean weather data\n",
    "\n",
    "**Considerations:**\n",
    "\n",
    "NaN/blank cannot be assumed to be zero.\n",
    "\n",
    "s = suspect value (appears with value)\n",
    "\n",
    "T = trace precipitation amount or snow depth (an amount too small to measure, usually < 0.005 inches water equivalent) (appears instead of numeric value)\n",
    "\n",
    "M = missing value (appears instead of value)\n",
    "\n",
    "Blank = value is unreported (appears instead of value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of weather: 27186\n",
      "Number of NaN/blank values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                             0\n",
       "HourlyAltimeterSetting        4696\n",
       "HourlyDewPointTemperature     1815\n",
       "HourlyDryBulbTemperature      1815\n",
       "HourlyPrecipitation           6973\n",
       "HourlyPresentWeatherType     20107\n",
       "HourlyPressureChange         18567\n",
       "HourlyPressureTendency       18567\n",
       "HourlyRelativeHumidity        1815\n",
       "HourlySeaLevelPressure        6766\n",
       "HourlySkyConditions           2912\n",
       "HourlyStationPressure         2079\n",
       "HourlyVisibility              1810\n",
       "HourlyWetBulbTemperature      2079\n",
       "HourlyWindDirection           1850\n",
       "HourlyWindGustSpeed          23816\n",
       "HourlyWindSpeed               1817\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a lot of NaN values in the weather data. They cannot be assumed to be zero\n",
    "print(f\"Size of weather: {weather.shape[0]}\")\n",
    "print(\"Number of NaN/blank values in each column:\")\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove redundant columns\n",
    "\n",
    "HourlyAltimeterSetting: collinear with HourlyStationPressure\n",
    "\n",
    "HourlyPressureChange, HourlyPressureTendency: missing many values, redundant with HourlyStationPressure\n",
    "\n",
    "HourlySeaLevelPressure: a mapping of HourlyStationPressure.\n",
    "\n",
    "HourlyWindGustSpeed: missing many values, redundant with HourlyWindSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_clean = weather.drop([\"HourlyAltimeterSetting\", \"HourlyPressureChange\", \"HourlyPressureTendency\", \"HourlySeaLevelPressure\", \"HourlyWindGustSpeed\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid rows\n",
    "\n",
    "HourlyDryBulb is one of a set of 4 predictors that consistently occur together in most cases. Rows where they are missing are going to be missing crucial data, and should be removed to be interpolated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_clean = weather_clean[weather_clean[\"HourlyDryBulbTemperature\"].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of weather: 25371\n",
      "Number of NaN/blank values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                             0\n",
       "HourlyDewPointTemperature        0\n",
       "HourlyDryBulbTemperature         0\n",
       "HourlyPrecipitation           5161\n",
       "HourlyPresentWeatherType     18292\n",
       "HourlyRelativeHumidity           0\n",
       "HourlySkyConditions           1097\n",
       "HourlyStationPressure          264\n",
       "HourlyVisibility                 0\n",
       "HourlyWetBulbTemperature       264\n",
       "HourlyWindDirection             40\n",
       "HourlyWindSpeed                  7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Size of weather: {weather_clean.shape[0]}\")\n",
    "print(\"Number of NaN/blank values in each column:\")\n",
    "weather_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on remaining features**\n",
    "\n",
    "*HourlySkyConditions*: It is likely not worth including feature in models, due to difficulty in representation. It appears to have correlation with precipitation and weather metrics, indicating it might be useful in classifying entries for interpollating missing data points.\n",
    "\n",
    "The documentation suggests that the overall character of the sky can be classified by the topmost/final listed layer. This is how I will represent the feature.\n",
    "\n",
    "*HourlyPresentWeatherType*: Will need to be expanded as a dummy variable, because one measurement can have multiple values. We should be sure to consider additive effects of combined weather patterns.\n",
    "\n",
    "Each weather item is indicated to be light, moderate, and heavy. For now, I will avoid including this information. It may be worth expanding this info to additonal dummy variables if some weather type is shown to have usefulness.\n",
    "\n",
    "*HourlyPrecipitation*: Need to convert T (trace amount) to a number. I will use 0.01, as that seems to be used interchangably in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce HourlySkyConditions\n",
    "Coverage: CLR (clear sky), FEW (few clouds), SCT (scattered clouds), BKN (broken clouds), OVC (overcast), VV (obscured sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OVC', nan, 'SCT', 'FEW', 'BKN', 'CLR', 'VV', 'X'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduceSkyConditions(conditions):\n",
    "    condition = conditions.split(\" \")\n",
    "    if len(condition) >= 2:\n",
    "        condition = condition[-2]  # Take last condition ([-1] would be height of last condition)\n",
    "        condition = condition.split(\":\")[0]\n",
    "        return str(condition)\n",
    "    elif len(condition) == 1:\n",
    "        if condition[0] == \"CLR:00\":\n",
    "            return \"CLR\"\n",
    "        else:\n",
    "            return np.NaN\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "weather_clean[\"HourlySkyConditions\"] = weather_clean.apply(lambda x: reduceSkyConditions(str(x[\"HourlySkyConditions\"])), axis=1)\n",
    "weather_clean[\"HourlySkyConditions\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce present weather type\n",
    "\n",
    "Three values given, seperated by pipes. The first (AU, automatic sensor) seems to be most valid for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '+PL',\n",
       " '+RA',\n",
       " '+SN',\n",
       " '-DZ',\n",
       " '-FZ',\n",
       " '-PL',\n",
       " '-RA',\n",
       " '-SN',\n",
       " '-TS',\n",
       " 'BC',\n",
       " 'BL',\n",
       " 'BR',\n",
       " 'DZ',\n",
       " 'FG',\n",
       " 'FZ',\n",
       " 'GR',\n",
       " 'GS',\n",
       " 'HZ',\n",
       " 'MI',\n",
       " 'PL',\n",
       " 'RA',\n",
       " 'SN',\n",
       " 'SQ',\n",
       " 'TS',\n",
       " 'UP',\n",
       " 'VCTS'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify all used AU Codes\n",
    "\n",
    "au_codes = []\n",
    "\n",
    "def findAUCodes(conditions):\n",
    "    condition = conditions.split(\"|\")\n",
    "    if len(condition) > 1:\n",
    "        condition = condition[0]\n",
    "        condition = condition.split(\" \")\n",
    "        types = []\n",
    "        for cond in condition:\n",
    "            temp = cond.split(\":\")[0]\n",
    "#            if temp[0] == '-' or temp[0] == '+':\n",
    "#                temp = temp[1:]\n",
    "            types.append(temp)\n",
    "        return types\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "out = weather.apply(lambda x: findAUCodes(str(x[\"HourlyPresentWeatherType\"])), axis=1)\n",
    "\n",
    "for i in out:\n",
    "    if i is not None:\n",
    "        for j in i:\n",
    "            au_codes.append(j)\n",
    "\n",
    "set(au_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include possible AU codes from above block (option to ignore +/-)\n",
    "au_codes =  [\n",
    "                'BC',\n",
    "                'BL',\n",
    "                'BR',\n",
    "                'DZ',\n",
    "                'FG',\n",
    "                'FZ',\n",
    "                'GS',\n",
    "                'HZ',\n",
    "                'MI',\n",
    "                'PL',\n",
    "                'RA',\n",
    "                'SN',\n",
    "                'TS',\n",
    "                'VCTS'  # VCTS will co-occur with TS by this code, should be okay though. Can be improved with assumption that VCTS and TS are mutually exclusive\n",
    "            ]\n",
    "\n",
    "def reduceWeatherTypes(conditions):\n",
    "    condition = conditions.split(\"|\")\n",
    "    if len(condition) > 1:\n",
    "        condition = condition[0]\n",
    "        au_dummy = []\n",
    "        for au in au_codes:\n",
    "            au_dummy.append(int(au in condition))\n",
    "        return au_dummy\n",
    "    else:\n",
    "        return [0] * len(au_codes)\n",
    "    \n",
    "weather_type_dummies = weather_clean.apply(lambda x: reduceWeatherTypes(str(x[\"HourlyPresentWeatherType\"])), result_type='expand', axis=1)\n",
    "weather_type_dummies.columns = au_codes\n",
    "# weather_clean = weather_clean.drop([\"HourlyPresentWeatherType\"],axis=1)  # Should be done after NaN's are dealt with\n",
    "weather_clean = pd.concat([weather_clean, weather_type_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace T with number in HourlyPrecipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_clean.loc[weather_clean.HourlyPrecipitation == 'T', 'HourlyPrecipitation'] = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hourly summary data\n",
    "\n",
    "There's probably a ton of ways to do this. I will leverage here the observation that the measurements at 54 minute marks are the most consistently good. I will then map each of these hourly values to the nearest whole hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_summ = weather_clean[weather_clean[\"DATE\"].dt.minute == 54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of weather: 17526\n",
      "Number of NaN/blank values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                             0\n",
       "HourlyDewPointTemperature        0\n",
       "HourlyDryBulbTemperature         0\n",
       "HourlyPrecipitation            184\n",
       "HourlyPresentWeatherType     14209\n",
       "HourlyRelativeHumidity           0\n",
       "HourlySkyConditions            216\n",
       "HourlyStationPressure          216\n",
       "HourlyVisibility                 0\n",
       "HourlyWetBulbTemperature       216\n",
       "HourlyWindDirection              3\n",
       "HourlyWindSpeed                  3\n",
       "BC                               0\n",
       "BL                               0\n",
       "BR                               0\n",
       "DZ                               0\n",
       "FG                               0\n",
       "FZ                               0\n",
       "GS                               0\n",
       "HZ                               0\n",
       "MI                               0\n",
       "PL                               0\n",
       "RA                               0\n",
       "SN                               0\n",
       "TS                               0\n",
       "VCTS                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Size of weather: {weather_summ.shape[0]}\")\n",
    "print(\"Number of NaN/blank values in each column:\")\n",
    "weather_summ.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumptions to clean summary data:\n",
    "\n",
    "Many NaN around 2019-11-22. Maintenance? \n",
    "\n",
    "HourlyPrecipitation needs further investigation. Must beware T (Trace) values. Appears to be similar gaps to HourlySkyConditions\n",
    "\n",
    "HourlySkyConditions have gaps of missing data. Perhaps use a classifier to predict for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wade\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adjust each datetime to the nearest hour ***ROUNDING DOWN***\n",
    "weather_summ[\"DATE\"] = weather_summ[\"DATE\"].apply(lambda x: x.replace(minute=0))\n",
    "#weather_summ.set_index(\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733     2019-03-31 13:00:00\n",
      "4494    2019-09-04 06:00:00\n",
      "5637    2019-10-21 21:00:00\n",
      "6145    2019-11-12 01:00:00\n",
      "6397    2019-11-22 13:00:00\n",
      "6399    2019-11-22 15:00:00\n",
      "6668    2019-12-03 20:00:00\n",
      "6669    2019-12-03 21:00:00\n",
      "6837    2019-12-10 21:00:00\n",
      "6838    2019-12-10 22:00:00\n",
      "6839    2019-12-10 23:00:00\n",
      "6848    2019-12-11 08:00:00\n",
      "6854    2019-12-11 14:00:00\n",
      "6855    2019-12-11 15:00:00\n",
      "6907    2019-12-13 19:00:00\n",
      "6908    2019-12-13 20:00:00\n",
      "6932    2019-12-14 20:00:00\n",
      "12830   2020-08-16 14:00:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "all = pd.Series(data=pd.date_range(start=weather_summ[\"DATE\"].min(), end=weather_summ[\"DATE\"].max(), freq='H'))\n",
    "mask = all.isin(weather_summ[\"DATE\"].values)\n",
    "print(all[~mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fill in the missing data points. This can probably be done by using the averages of the other data points nearby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning power data\n",
    "\n",
    "It seems that some engines tend to show negative numbers consistently or during startup. This needs to be further investigated.\n",
    "\n",
    "Otherwise, power data can be converted to hourly information either by an average of all measurements in an hour or by sampling at regular hour intervals. Both methods are valid and produce similar results. The biggest proportional difference occurs in the small (sub 5000 Tonnes) power ranges. Ways to calculate each and compare in Excel are given below.\n",
    "\n",
    "There might be appliations where a max or min value over an hour will be useful as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```=AVERAGE(OFFSET(power!$K$2,(ROW(A1)-1)*60,,60,))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```=OFFSET(power!$K$2,(ROW(B1)-1)*60,,1,)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```=(B1-A1)/B1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No cleaning done yet\n",
    "power_clean = power[[\"DATE\",\"Total Power\"]]\n",
    "#power_clean = power.set_index([\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218    2019-03-10 02:00:00\n",
      "8954   2020-03-08 02:00:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Check for time series continuity\n",
    "all = pd.Series(data=pd.date_range(start=power_clean[\"DATE\"].min(), end=power_clean[\"DATE\"].max(), freq='H'))\n",
    "mask = all.isin(power_clean[\"DATE\"].values)\n",
    "print(all[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This value should be zero to be consistent with surrounding data values\n",
    "missing_val = pd.DataFrame([[pd.Timestamp(\"2019-03-10 02:00:00\"), 0],[pd.Timestamp(\"2020-03-08 02:00:00\"), 0]], columns=['DATE','Total Power'])\n",
    "power_clean = power_clean.append(missing_val, ignore_index=True)\n",
    "\n",
    "power_clean = power_clean.sort_values(['DATE'])\n",
    "power_clean = power_clean.reset_index(drop=True)\n",
    "power_clean = power_clean[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to hourly summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min and Max need to be fixed, currently they match all rows with min/max values, should only match those with right time and min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_summ_all = power_clean[power_clean['DATE'].dt.minute == 30][['DATE']]\n",
    "power_summ_all[\"DATE\"] = power_summ_all[\"DATE\"].apply(lambda x: x.replace(minute=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_summ_max = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour], sort=False)['Total Power'].max().tolist()\n",
    "power_summ_all['Total Power (max)'] = power_summ_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_summ_min = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour], sort=False)['Total Power'].min().tolist()\n",
    "power_summ_all['Total Power (min)'] = power_summ_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_summ_avg = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour], sort=False)['Total Power'].mean().tolist()\n",
    "power_summ_all['Total Power (avg)'] = power_summ_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regular interval hourly (on top of the hour)\n",
    "power_summ_idx = power_clean['DATE'].dt.minute == 54\n",
    "power_summ_samp = power_clean[power_summ_idx]['Total Power'].tolist()\n",
    "power_summ_all['Total Power (samp)'] = power_summ_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get max hourly (not functional currently)\n",
    "#power_summ_idx = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour], sort=False)['Total Power'].transform(max) == power_clean['Total Power']\n",
    "#power_summ_max = power_clean[power_summ_idx]\n",
    "#power_summ_max[\"DATE\"] = power_summ_max[\"DATE\"].apply(lambda x: x.replace(minute=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wade\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Get min hourly (not functional currently)\n",
    "#power_summ_idx = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour], sort=False)['Total Power'].transform(min) == power_clean['Total Power']\n",
    "#power_summ_min = power_clean[power_summ_idx]\n",
    "#ower_summ_min[\"DATE\"] = power_summ_min[\"DATE\"].apply(lambda x: x.replace(minute=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average hourly\n",
    "#avg_power_hourly = power_clean.groupby([power_clean[\"DATE\"].dt.year, power_clean[\"DATE\"].dt.dayofyear, power_clean[\"DATE\"].dt.hour]).mean()\n",
    "\n",
    "#power_summ_idx = power_clean['DATE'].dt.minute == 0\n",
    "#power_summ_avg = power_clean[power_summ_idx]\n",
    "\n",
    "#power_summ_avg['Total Power'] = avg_power_hourly['Total Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wade\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Get regular interval hourly (on top of the hour)\n",
    "#power_summ_idx = power_clean['DATE'].dt.minute == 54\n",
    "#power_summ_reg = power_clean[power_summ_idx]\n",
    "#power_summ_reg[\"DATE\"] = power_summ_reg[\"DATE\"].apply(lambda x: x.replace(minute=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(power_summ_all, weather_summ, how=\"left\", on='DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate missing data\n",
    "Temporary solution for now, fill in NaN rows with row above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, column HourlyPresentWeatherType can be removed, if nothin is present, if should be clear\n",
    "data = data.drop(['HourlyPresentWeatherType'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: 17544\n",
      "Number of NaN/blank values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                         0\n",
       "Total Power (max)            0\n",
       "Total Power (min)            0\n",
       "Total Power (avg)            0\n",
       "Total Power (samp)           0\n",
       "HourlyDewPointTemperature    0\n",
       "HourlyDryBulbTemperature     0\n",
       "HourlyPrecipitation          0\n",
       "HourlyRelativeHumidity       0\n",
       "HourlySkyConditions          0\n",
       "HourlyStationPressure        0\n",
       "HourlyVisibility             0\n",
       "HourlyWetBulbTemperature     0\n",
       "HourlyWindDirection          0\n",
       "HourlyWindSpeed              0\n",
       "BC                           0\n",
       "BL                           0\n",
       "BR                           0\n",
       "DZ                           0\n",
       "FG                           0\n",
       "FZ                           0\n",
       "GS                           0\n",
       "HZ                           0\n",
       "MI                           0\n",
       "PL                           0\n",
       "RA                           0\n",
       "SN                           0\n",
       "TS                           0\n",
       "VCTS                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Size of data: {data.shape[0]}\")\n",
    "print(\"Number of NaN/blank values in each column:\")\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [DATE, Total Power (max), Total Power (min), Total Power (avg), Total Power (samp), HourlyDewPointTemperature, HourlyDryBulbTemperature, HourlyPrecipitation, HourlyRelativeHumidity, HourlySkyConditions, HourlyStationPressure, HourlyVisibility, HourlyWetBulbTemperature, HourlyWindDirection, HourlyWindSpeed, BC, BL, BR, DZ, FG, FZ, GS, HZ, MI, PL, RA, SN, TS, VCTS]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data.HourlyWetBulbTemperature.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
