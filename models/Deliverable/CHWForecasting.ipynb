{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External packages:\n",
    "try:\n",
    "    import cPickle as pickle  # cPickle is faster, but not as complete\n",
    "    \n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHWForecasting:\n",
    "    \n",
    "    def CHWForecasting(self, model_file = None):\n",
    "        \"\"\"Creates a chilled water forcasting object. Loads an earlier model from file if 'model_file' is specified.\"\"\"\n",
    "        self._hourly_model = None\n",
    "        self._daily_model = None\n",
    "        self._hrs_before = None\n",
    "        self._hrs_after = None\n",
    "        self._days_before = None\n",
    "        self._days_after = None\n",
    "        self._daily_significance = None\n",
    "        \n",
    "        if model_file is not None:\n",
    "            # Unpickle here...\n",
    "            self.load(model_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # User methods\n",
    "    \n",
    "    def build_hourly_model(self, hourly_power, hourly_weather, hrs_before, hrs_after):\n",
    "        \"\"\"\n",
    "        Build and train model using 'hourly power' and 'hourly weather' as training data.\n",
    "        \n",
    "        Use hrs_before and hrs_after to specify the range data should be windowed to. hrs_after should match the \n",
    "        numbers of hours the future preditions will be made on.\n",
    "        \"\"\"\n",
    "        hourly = pd.merge(hourly_power, hourly_weather, on = 'DATE')\n",
    "        hourly['DATE'] = hourly.apply(lambda x: pd.Timestamp(x['DATE']), axis=1)\n",
    "        \n",
    "        past_features = hourly.columns.tolist()\n",
    "        past_features.remove('DATE')\n",
    "        \n",
    "        future_features = hourly_weather.columns.tolist()\n",
    "        future_features.remove('DATE')\n",
    "\n",
    "        #past_features = ['Total Power (trimmed)', 'HourlyDryBulbTemperature', 'HourlyWetBulbTemperature']\n",
    "        #future_features = ['HourlyDryBulbTemperature', 'HourlyWetBulbTemperature']\n",
    "\n",
    "        hourlyWindowed = self.windowData(hourly, npast = hrs_before, nfuture = hrs_after, colpast = past_features, colfuture = future_features)\n",
    "        hourlyWindowed = self.genTSfeats(windowedDF = hourlyWindowed, windows = [22])  \n",
    "        hourlyWindowed = self.addTimeFeatures(hourlyWindowed)\n",
    "        X, Ys = self.genXY(hourlyWindowed, 'Total Power (trimmed)', maxoffset = hrs_after)\n",
    "        \n",
    "        all_model = []\n",
    "        all_rmse = []\n",
    "        \n",
    "        for Y in Ys:\n",
    "            model, mae, rmse, rsq = self.runModel(X, Y, model=ExtraTreesRegressor())\n",
    "            all_model.append(model)\n",
    "            all_rmse.append(rmse)\n",
    "        \n",
    "        self._hourly_model = [all_model, all_rmse]\n",
    "    \n",
    "    def build_daily_model(self, hourly_power, hourly_weather, days_before, days_after, significance = 0.85):\n",
    "        \"\"\"\n",
    "        Build and train model using 'hourly power' and 'hourly weather' as training data.\n",
    "        \n",
    "        Use hrs_before and hrs_after to specify the range data should be windowed to. hrs_after should match the \n",
    "        numbers of hours in the future preditions will be made on.\n",
    "        \"\"\"\n",
    "        train = pd.merge(hourly_power, hourly_weather, on = \"DATE\")\n",
    "        self._daily_significance = significance\n",
    "        self._daily_model = self.trainGB_ndays(train, significance = significance)\n",
    "\n",
    "    \n",
    "    def predict_hourly_forecast(self, date_and_time, recent_power, recent_weather, forecasted_weather):\n",
    "        \"\"\" Creates a forecast object for this class using provided data to give predictions. \"\"\"\n",
    "        \n",
    "        recent = pd.merge(recent_power, recent_weather, on = 'DATE')\n",
    "        \n",
    "        past_features = recent.columns.tolist()\n",
    "        past_features.remove('DATE')\n",
    "    \n",
    "        future_features = forecasted_weather.columns.tolist()\n",
    "        future_features.remove('DATE')\n",
    "        \n",
    "        merged = recent.append(forecasted_weather, sort = False)\n",
    "        merged[\"DATE\"] = merged.apply(lambda x: pd.Timestamp(x[\"DATE\"]), axis=1)\n",
    "        merged.reset_index()\n",
    "        \n",
    "        windowed = self.windowData(merged, npast = len(recent_power)-1, nfuture = len(forecasted_weather)-1, colpast = past_features, colfuture = future_features)\n",
    "        windowed_ts = self.genTSfeats(windowedDF = windowed, windows = [22])\n",
    "        self.addTimeFeatures(windowed_ts)\n",
    "        \n",
    "        df = windowed_ts.dropna()\n",
    "        df = df.drop(columns = ['DATE'])\n",
    "        \n",
    "        all_pred = []\n",
    "\n",
    "        for m in self._hourly_model[0]:\n",
    "            all_pred.append(m.predict(df))\n",
    "        \n",
    "        max_power = max(all_pred) # peak power (tons)\n",
    "        peak_future_hour = all_pred.index(max_power) \n",
    "        max_power_error = self._hourly_model[1][peak_future_hour] \n",
    "        pred_int = (max_power[0] - (2*max_power_error), max_power[0] + (2*max_power_error)) \n",
    "        \n",
    "        current_date_and_time = pd.to_datetime(date_and_time) # assuming date_and_time gets passed in as a string in the form 'MM-DD-YYYY HH:MM:SS'\n",
    "        hours_to_add = datetime.timedelta(hours = peak_future_hour + 1)\n",
    "        peak_timestamp = current_date_and_time + hours_to_add\n",
    "        \n",
    "        return max_power, peak_timestamp, pred_int\n",
    "    \n",
    "    def predict_daily_forecast(self, recent_power, recent_weather, forecasted_weather, day_out=1):\n",
    "        \"\"\"Creates a forecast object for this class using provided data to give predictions.\"\"\"\n",
    "        predictDf = pd.merge(recent_power, recent_weather.append(forecasted_weather), on = 'DATE', how ='outer')\n",
    "        return self.predict(predictDf, nDays=day_out, modelList=self._daily_model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Hourly model methods\n",
    "    \n",
    "    def windowData(self, df, npast=0, nfuture=0, colpast=[], colfuture=[]):\n",
    "    \n",
    "        # Add past windows:\n",
    "        kept_past = df[colpast]  # elements used in past windows...\n",
    "        for i in range(1, npast+1):\n",
    "            temp = kept_past.shift(i)\n",
    "            temp.columns = [f\"{c}-{i}hr\" for c in kept_past.columns]\n",
    "            df = pd.concat([df,temp], axis=1)\n",
    "        \n",
    "        # Add future windows:\n",
    "        kept_future = df[colfuture]  # elements used future windows...\n",
    "        for i in range(1, nfuture+1):\n",
    "            temp = kept_future.shift(-i)\n",
    "            temp.columns = [f\"{c}+{i}hr\" for c in kept_future.columns]\n",
    "            df = pd.concat([df,temp], axis=1)\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def genTSfeats(self, windowedDF, windows = []): \n",
    "\n",
    "        for win in windows: # Loop over windows of different sizes, if passed--22 is optimal.\n",
    "\n",
    "            # Generate temporary 'lookback' dataframes for feature construction:\n",
    "            tmp_power = windowedDF.iloc[:, 4:(3*win)+4:3]\n",
    "            tmp_drybulb = windowedDF.iloc[:, 5:(3*win)+5:3]\n",
    "            tmp_wetbulb = windowedDF.iloc[:, 6:(3*win)+6:3]\n",
    "\n",
    "            tmp_dfs = [tmp_power, tmp_drybulb, tmp_wetbulb]\n",
    "            var_names = ['power', 'drybulb', 'wetbulb']\n",
    "\n",
    "            # Loop over temporary dataframes and construct desired features:\n",
    "            for tmp, var in zip(tmp_dfs, var_names):\n",
    "                \n",
    "                # General statistics for base level.\n",
    "                windowedDF[f'meanprev{win}_{var}'] = tmp.mean(axis=1)\n",
    "                windowedDF[f'medianprev{win}_{var}'] = tmp.median(axis=1)\n",
    "                windowedDF[f'minprev{win}_{var}'] = tmp.min(axis=1)\n",
    "                windowedDF[f'maxprev{win}_{var}'] = tmp.max(axis=1)\n",
    "                windowedDF[f'stdprev{win}_{var}'] = tmp.std(axis=1)\n",
    "\n",
    "                # Capturing trend.\n",
    "                windowedDF[f'mean_ewmprev{win}_{var}'] = tmp.T.ewm(com=9.5).mean().T.mean(axis=1)\n",
    "                windowedDF[f'last_ewmprev{win}_{var}'] = tmp.T.ewm(com=9.5).mean().T.iloc[:,-1]\n",
    "                windowedDF[f'avgdiff{win}_{var}'] = (tmp - tmp.shift(1, axis=1)).mean(axis=1)\n",
    "\n",
    "        return windowedDF\n",
    "    \n",
    "    def addTimeFeatures(self, df):\n",
    "        \n",
    "        # Month:\n",
    "        months = df.apply(lambda x: x[\"DATE\"].month, axis=1)\n",
    "        df['month_sin'] = np.sin((months-1)*(2.*np.pi/12))\n",
    "        df['month_cos'] = np.cos((months-1)*(2.*np.pi/12))\n",
    "\n",
    "        # Day of Week:\n",
    "        dow = df.apply(lambda x: x[\"DATE\"].dayofweek, axis=1)\n",
    "        df['DoW_sin'] = np.sin(dow*(2.*np.pi/7))\n",
    "        df['DoW_cos'] = np.cos(dow*(2.*np.pi/7))\n",
    "\n",
    "        # Hour of Day:\n",
    "        hr = df.apply(lambda x: x[\"DATE\"].hour, axis=1)\n",
    "        df['Hour_sin'] = np.sin(hr*(2.*np.pi/24))\n",
    "        df['Hour_cos'] = np.cos(hr*(2.*np.pi/24))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def addTimeFeatures_daily(self, df): #Add time features to daily max prediction model\n",
    "        #Get month sin and cos columns from existing date column\n",
    "        months = df.apply(lambda x: x[\"DATE\"].month, axis=1)\n",
    "        df['month_sin'] = np.sin((months-1)*(2.*np.pi/12))\n",
    "        df['month_cos'] = np.cos((months-1)*(2.*np.pi/12))\n",
    "        \n",
    "        #Get weekday sin and cos columns from existing weekday column\n",
    "        df['DoW_sin'] = np.sin(df['weekday']*(2.*np.pi/7))\n",
    "        df['DoW_cos'] = np.cos(df['weekday']*(2.*np.pi/7))\n",
    "    \n",
    "    def genXY(self, X, target_var, maxoffset = 1):\n",
    "        '''\n",
    "        Generate X and Y data to be used in run model. X should be untrimmed (include NaNs).\n",
    "        Will return tuple contianing trimmed X and list of Y vectors with offset ranging from 1 to maxoffset.\n",
    "        '''\n",
    "        df = X.copy()\n",
    "        Y = []\n",
    "\n",
    "        for l in range(1, maxoffset+1):\n",
    "            df[f\"offset_{l}\"] = df[target_var].shift(-l)\n",
    "\n",
    "        df = df.dropna()\n",
    "        df = df.reset_index(drop = True)\n",
    "        df = df.drop(columns = ['DATE'])\n",
    "\n",
    "        for l in range(1, maxoffset+1):\n",
    "            Y.append(df[f\"offset_{l}\"])\n",
    "            df.drop(columns=[f\"offset_{l}\"], inplace = True)\n",
    "\n",
    "        return (df, Y)\n",
    "    \n",
    "    def runModel(self, X, Y, model, verbose=False):\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8, random_state = 12345, shuffle = True)  # Create train & test sets.\n",
    "        model.fit(X_train, Y_train)  # Fit model...\n",
    "\n",
    "        # Calculate error metrics:\n",
    "        rsq = model.score(X_test, Y_test)\n",
    "        rmse = math.sqrt(metrics.mean_squared_error(Y_test, model.predict(X_test)))\n",
    "        mae = metrics.mean_absolute_error(Y_test, model.predict(X_test))\n",
    "\n",
    "        # Display if selected in arguments:\n",
    "        if verbose:\n",
    "            print(\"R Squared Score: {:.4f}\".format(rsq))\n",
    "            print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "            print(\"Mean Absolute Error: {:.2f}\".format(mae))\n",
    "\n",
    "        return model, mae, rmse, rsq\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Daily model methods\n",
    "    \n",
    "    def formatTrainingData(self, df, nDays, trainDays = 7): #Format the training data for building the models for nDays from prediction\n",
    "    \n",
    "        df[\"DATE\"] = df.apply(lambda x: pd.Timestamp(x[\"DATE\"]), axis=1) #Convert date to timestamp formate\n",
    "        df['DATE'] = [d.date() for d in df[\"DATE\"]] #Get just the date and remove time associations\n",
    "\n",
    "        groupby = df.groupby('DATE').describe() #Group rows with the same date together\n",
    "\n",
    "        colList = df.drop(columns = ['DATE']).columns #Get list of non-date columns\n",
    "        parameters = ['min', 'max', 'mean']\n",
    "\n",
    "        dailyData = {'DATE':list(groupby.index)} #Dictionary to begin building the training df from\n",
    "\n",
    "        nday_cols = [] #List of non-power columns\n",
    "        \n",
    "        for col in colList: #Iterate through list of non-date columns\n",
    "            if(col == 'Total Power (trimmed)_max'):\n",
    "                dailyData[col] = list(groupby[col]['max']) #Add max value of total power to data dictionary\n",
    "            else: #Add min, max, and mean columns for all non-power columns to data dictionary                                     \n",
    "                for param in parameters:\n",
    "                    colname = col + \"_\" + param\n",
    "                    dailyData[colname] = list(groupby[col][param])\n",
    "                    nday_cols.append(colname) #Add new column to list of non-power columns\n",
    "                    \n",
    "        daily = pd.DataFrame(dailyData) #Convert data dictionary to a data frame\n",
    "\n",
    "        daily['weekday'] = [row['DATE'].weekday() for i, row in daily.iterrows()] #Get weekday column from date\n",
    "        \n",
    "        if(nDays > 0):\n",
    "            for col in nday_cols: #Iterate through non-date or power columns\n",
    "                #Shift all weather columns i days from the day being predicted for up to trainDays before the day the prediction is being made\n",
    "                for i in range(nDays + trainDays): \n",
    "                    colname = col + \"-\" + str(i + 1) + \"day\"\n",
    "                    daily[colname] = daily[col].shift(i+1)\n",
    "            \n",
    "            #Shift max power column i days from the day when the prediction is made up to trainDays before    \n",
    "            for i in range(nDays, trainDays + nDays + 1):\n",
    "                colname = 'Total Power (trimmed)_max' + \"-\" + str(i) + \"day\"\n",
    "                daily[colname] = daily['Total Power (trimmed)_max'].shift(i)\n",
    "\n",
    "        self.addTimeFeatures_daily(daily) #Add sin and cos columns for month and weekday\n",
    "\n",
    "        daily = daily.dropna() #Remove null values\n",
    "        return daily #Return cleaned df for training\n",
    "    \n",
    "    #Method to train GB models for 1-5 days into the future        \n",
    "    def trainGB_ndays(self, df, predictorVar = 'Total Power (trimmed)_max', dropCols = ['DATE'], significance = 0.85):\n",
    "        gb_modelList = [] #List that will store the lists of models\n",
    "        for i in range(5): #For day 1-5\n",
    "            days = i+1\n",
    "            dailyMaxModels = self.trainGB_Model(df, days, predictorVar, dropCols, significance) #Train the 3 GB models for that number of days with specified significance level\n",
    "            gb_modelList.append(dailyMaxModels) #Add that list of 3 models to the list of models\n",
    "\n",
    "        return gb_modelList #Return the list of models (should include 5 lists with 3 elements)\n",
    "    \n",
    "    def trainGB_Model(self, df, days, predictorVar, dropCols, significance): #Method to train the GB model\n",
    "        dropCols.append(predictorVar) #Make sure we drop the column being predicted (Max Power)\n",
    "\n",
    "        daily = self.formatTrainingData(df, nDays = days) #Prepare the training data\n",
    "\n",
    "        # Set lower and upper quantile\n",
    "        LOWER_ALPHA = (1 - significance)/2\n",
    "        UPPER_ALPHA = 1-LOWER_ALPHA\n",
    "\n",
    "        # Model for lower bound of prediction interval\n",
    "        lower = GradientBoostingRegressor(loss=\"quantile\",                   \n",
    "                                                alpha=LOWER_ALPHA)\n",
    "        \n",
    "        # The mid model will use the default loss - this is the value being predicted\n",
    "        mid = GradientBoostingRegressor(loss=\"ls\")\n",
    "        \n",
    "        # Model for upper bound of prediction interval\n",
    "        upper = GradientBoostingRegressor(loss=\"quantile\",\n",
    "                                                alpha=UPPER_ALPHA)\n",
    "        \n",
    "        X = daily.drop(dropCols, axis=1) #Drop the unnecessary columns from data for training\n",
    "        Y = daily[predictorVar] #Column being predicted\n",
    "\n",
    "        #train the 3 models separately\n",
    "        lower.fit(X, Y)\n",
    "        mid.fit(X, Y)\n",
    "        upper.fit(X, Y)\n",
    "\n",
    "        return [lower, mid, upper] #Return list of lower middle and upper models\n",
    "    \n",
    "    def prepPredict(self, df, nDays, trainDays = 7): #Method to prepare data to be predicted on\n",
    "        df[\"DATE\"] = df.apply(lambda x: pd.Timestamp(x[\"DATE\"]), axis=1) #Convert date to timestamp form\n",
    "        df['DATE'] = [d.date() for d in df[\"DATE\"]] #Get date from timestamps\n",
    "\n",
    "        for index in range(len(df)): #Iterate through each row\n",
    "            if(df.loc[index]['Total Power (trimmed)_max'] != df.loc[index]['Total Power (trimmed)_max']): #Check if max power is null\n",
    "                today = index-1 #Today would be the day before the max power is null because it's the last day with known power\n",
    "                predictDay = today + nDays #Day we are making the prediction for is nDays after today\n",
    "                break #Break once we get first null power value\n",
    "\n",
    "        testDf = df.copy() #Copy the df\n",
    "\n",
    "        if(nDays > 0):\n",
    "            for col in testDf.columns[2:]:\n",
    "                #Shift all weather columns i days from the day being predicted for up to trainDays before the day the prediction is being made\n",
    "                for i in range(nDays + trainDays):\n",
    "                    colname = col + \"-\" + str(i + 1) + \"day\"\n",
    "                    testDf[colname] = testDf[col].shift(i+1)\n",
    "            \n",
    "            #Shift max power column i days from the day when the prediction is made up to trainDays before    \n",
    "            powerCol = testDf.columns[1] #Shift power \n",
    "            for i in range(nDays, trainDays + nDays + 1):\n",
    "                colname = powerCol + \"-\" + str(i) + \"day\"\n",
    "                testDf[colname] = testDf[powerCol].shift(i)\n",
    "\n",
    "        testDf['weekday'] = [row['DATE'].weekday() for i, row in testDf.iterrows()] #Add weekday to df\n",
    "        self.addTimeFeatures_daily(testDf) #Add sin and cos columns for weekday and month\n",
    "\n",
    "        return testDf.loc[predictDay] #Return the 1 row for the day we would like to predict for\n",
    "\n",
    "    def predict(self, df, nDays, modelList): #Method to make a prediction\n",
    "        test = self.prepPredict(df, nDays) #Get row being predicted on\n",
    "        date = test['DATE'] #Make a note of what day is being predicted for\n",
    "        testDf = pd.DataFrame(test.values.reshape(1,-1) , columns = test.index) #Reshape data because it is only one row\n",
    "\n",
    "        X = testDf.drop(columns = ['DATE', 'Total Power (trimmed)_max']) #Drop unnecessary columns\n",
    "\n",
    "        lower = modelList[nDays - 1][0].predict(X)[0] #Predict lower boundary of prediction interval\n",
    "        mid = modelList[nDays - 1][1].predict(X)[0] #Get predicted value\n",
    "        upper = modelList[nDays - 1][2].predict(X)[0] #Predict upper boundary of prediction interval\n",
    "\n",
    "        #print(f'{date}: {mid} ({lower},{upper})')\n",
    "        return mid, date, (lower, upper) #Return the predicted value, the date, and the prediction interval\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Model saving and loading functions\n",
    "    \n",
    "    def load(self, filename):\n",
    "        \"\"\"  \"\"\"\n",
    "        f = open(filename, 'rb')\n",
    "        tmp_dict = pickle.load(f)\n",
    "        f.close()          \n",
    "        self.__dict__.clear()\n",
    "        self.__dict__.update(tmp_dict) \n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"  \"\"\"\n",
    "        f = open(filename, 'wb')\n",
    "        pickle.dump(self.__dict__, f, 2)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_power = pd.read_csv('hourly_power.csv')\n",
    "hourly_weather = pd.read_csv('hourly_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_power = pd.read_csv('recent_power.csv')\n",
    "recent_weather = pd.read_csv('recent_weather.csv')\n",
    "forecasted_weather = pd.read_csv('forecasted_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_forecasted_weather = pd.read_csv('daily_forecasted_weather.csv')\n",
    "daily_recent_weather = pd.read_csv('daily_recent_weather.csv')\n",
    "daily_recent_power = pd.read_csv('daily_recent_power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = CHWForecasting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_model_w_errors = forecast.build_hourly_model(hourly_power, hourly_weather, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forecast.predict_hourly_forecast('2020-04-20 17:00:00', recent_power, recent_weather, forecasted_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3192.05078125]),\n",
       " Timestamp('2020-04-21 06:00:00'),\n",
       " (2292.833163584572, 4091.268398915428))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = CHWForecasting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.build_daily_model(hourly_power, hourly_weather, days_before=7, days_after=5, significance = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-30: 11275.641550280918 (12377.635676047397,16296.064352271864)\n",
      "2019-07-01: 14272.834435484987 (11190.495730749943,15420.5163426715)\n",
      "2019-07-02: 14397.382728538074 (9902.92163990516,17578.44544759516)\n",
      "2019-07-03: 16867.580064366324 (12172.816733940328,17705.696337598405)\n",
      "2019-07-04: 16983.863394559907 (12473.061727087459,18100.54754224029)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    forecast.predict_daily_forecast(daily_recent_power, daily_recent_weather, daily_forecasted_weather, day_out=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_forecast = CHWForecasting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_forecast.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-30: 11275.641550280918 (12377.635676047397,16296.064352271864)\n",
      "2019-07-01: 14272.834435484987 (11190.495730749943,15420.5163426715)\n",
      "2019-07-02: 14397.382728538074 (9902.92163990516,17578.44544759516)\n",
      "2019-07-03: 16867.580064366324 (12172.816733940328,17705.696337598405)\n",
      "2019-07-04: 16983.863394559907 (12473.061727087459,18100.54754224029)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    load_forecast.predict_daily_forecast(daily_recent_power, daily_recent_weather, daily_forecasted_weather, day_out=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>Total Power (trimmed)_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>2019-06-22 23:00:00</td>\n",
       "      <td>9971.835401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>2019-06-23 23:00:00</td>\n",
       "      <td>13077.625195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>2019-06-24 23:00:00</td>\n",
       "      <td>13351.757068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>2019-06-25 23:00:00</td>\n",
       "      <td>12941.737036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>2019-06-26 23:00:00</td>\n",
       "      <td>13264.739941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118</td>\n",
       "      <td>2019-06-27 23:00:00</td>\n",
       "      <td>13099.856531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>119</td>\n",
       "      <td>2019-06-28 23:00:00</td>\n",
       "      <td>12928.747217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120</td>\n",
       "      <td>2019-06-29 23:00:00</td>\n",
       "      <td>13139.119617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 DATE  Total Power (trimmed)_max\n",
       "0         113  2019-06-22 23:00:00                9971.835401\n",
       "1         114  2019-06-23 23:00:00               13077.625195\n",
       "2         115  2019-06-24 23:00:00               13351.757068\n",
       "3         116  2019-06-25 23:00:00               12941.737036\n",
       "4         117  2019-06-26 23:00:00               13264.739941\n",
       "5         118  2019-06-27 23:00:00               13099.856531\n",
       "6         119  2019-06-28 23:00:00               12928.747217\n",
       "7         120  2019-06-29 23:00:00               13139.119617"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_recent_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyWetBulbTemperature_max</th>\n",
       "      <th>HourlyDryBulbTemperature_max</th>\n",
       "      <th>HourlyWetBulbTemperature_min</th>\n",
       "      <th>HourlyDryBulbTemperature_min</th>\n",
       "      <th>HourlyWetBulbTemperature_mean</th>\n",
       "      <th>HourlyDryBulbTemperature_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>2019-06-22 23:00:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>56.958333</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>2019-06-23 23:00:00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.625000</td>\n",
       "      <td>68.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>2019-06-24 23:00:00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>64.166667</td>\n",
       "      <td>71.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>2019-06-25 23:00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.041667</td>\n",
       "      <td>73.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>2019-06-26 23:00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>74.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118</td>\n",
       "      <td>2019-06-27 23:00:00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.458333</td>\n",
       "      <td>73.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>119</td>\n",
       "      <td>2019-06-28 23:00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>76.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120</td>\n",
       "      <td>2019-06-29 23:00:00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.916667</td>\n",
       "      <td>76.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 DATE  HourlyWetBulbTemperature_max  \\\n",
       "0         113  2019-06-22 23:00:00                          61.0   \n",
       "1         114  2019-06-23 23:00:00                          64.0   \n",
       "2         115  2019-06-24 23:00:00                          71.0   \n",
       "3         116  2019-06-25 23:00:00                          70.0   \n",
       "4         117  2019-06-26 23:00:00                          70.0   \n",
       "5         118  2019-06-27 23:00:00                          68.0   \n",
       "6         119  2019-06-28 23:00:00                          70.0   \n",
       "7         120  2019-06-29 23:00:00                          71.0   \n",
       "\n",
       "   HourlyDryBulbTemperature_max  HourlyWetBulbTemperature_min  \\\n",
       "0                          77.0                          51.0   \n",
       "1                          81.0                          52.0   \n",
       "2                          82.0                          56.0   \n",
       "3                          79.0                          61.0   \n",
       "4                          85.0                          60.0   \n",
       "5                          86.0                          58.0   \n",
       "6                          88.0                          61.0   \n",
       "7                          83.0                          63.0   \n",
       "\n",
       "   HourlyDryBulbTemperature_min  HourlyWetBulbTemperature_mean  \\\n",
       "0                          54.0                      56.958333   \n",
       "1                          54.0                      58.625000   \n",
       "2                          58.0                      64.166667   \n",
       "3                          66.0                      66.041667   \n",
       "4                          64.0                      64.333333   \n",
       "5                          60.0                      64.458333   \n",
       "6                          63.0                      65.750000   \n",
       "7                          68.0                      67.916667   \n",
       "\n",
       "   HourlyDryBulbTemperature_mean  \n",
       "0                      66.666667  \n",
       "1                      68.666667  \n",
       "2                      71.791667  \n",
       "3                      73.583333  \n",
       "4                      74.625000  \n",
       "5                      73.541667  \n",
       "6                      76.250000  \n",
       "7                      76.708333  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_recent_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyWetBulbTemperature_max</th>\n",
       "      <th>HourlyDryBulbTemperature_max</th>\n",
       "      <th>HourlyWetBulbTemperature_min</th>\n",
       "      <th>HourlyDryBulbTemperature_min</th>\n",
       "      <th>HourlyWetBulbTemperature_mean</th>\n",
       "      <th>HourlyDryBulbTemperature_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>2019-06-30 23:00:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.291667</td>\n",
       "      <td>68.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>2019-07-01 23:00:00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.625000</td>\n",
       "      <td>69.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>2019-07-02 23:00:00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.875000</td>\n",
       "      <td>73.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>2019-07-03 23:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.291667</td>\n",
       "      <td>76.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>2019-07-04 23:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.791667</td>\n",
       "      <td>78.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 DATE  HourlyWetBulbTemperature_max  \\\n",
       "0         121  2019-06-30 23:00:00                          63.0   \n",
       "1         122  2019-07-01 23:00:00                          66.0   \n",
       "2         123  2019-07-02 23:00:00                          71.0   \n",
       "3         124  2019-07-03 23:00:00                          72.0   \n",
       "4         125  2019-07-04 23:00:00                          75.0   \n",
       "\n",
       "   HourlyDryBulbTemperature_max  HourlyWetBulbTemperature_min  \\\n",
       "0                          74.0                          56.0   \n",
       "1                          79.0                          53.0   \n",
       "2                          80.0                          60.0   \n",
       "3                          85.0                          64.0   \n",
       "4                          89.0                          63.0   \n",
       "\n",
       "   HourlyDryBulbTemperature_min  HourlyWetBulbTemperature_mean  \\\n",
       "0                          59.0                      60.291667   \n",
       "1                          55.0                      60.625000   \n",
       "2                          67.0                      66.875000   \n",
       "3                          66.0                      68.291667   \n",
       "4                          65.0                      70.791667   \n",
       "\n",
       "   HourlyDryBulbTemperature_mean  \n",
       "0                      68.083333  \n",
       "1                      69.666667  \n",
       "2                      73.500000  \n",
       "3                      76.250000  \n",
       "4                      78.916667  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_forecasted_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
