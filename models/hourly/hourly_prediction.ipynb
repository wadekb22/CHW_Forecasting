{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>Total Power (max)</th>\n",
       "      <th>Total Power (min)</th>\n",
       "      <th>Total Power (avg)</th>\n",
       "      <th>Total Power (samp)</th>\n",
       "      <th>Total Power (trimmed)</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>...</th>\n",
       "      <th>FG</th>\n",
       "      <th>FZ</th>\n",
       "      <th>GS</th>\n",
       "      <th>HZ</th>\n",
       "      <th>MI</th>\n",
       "      <th>PL</th>\n",
       "      <th>RA</th>\n",
       "      <th>SN</th>\n",
       "      <th>TS</th>\n",
       "      <th>VCTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-03-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 DATE  Total Power (max)  Total Power (min)  \\\n",
       "0           0  2019-03-01 00:00:00                0.0                0.0   \n",
       "1           1  2019-03-01 01:00:00                0.0                0.0   \n",
       "2           2  2019-03-01 02:00:00                0.0                0.0   \n",
       "3           3  2019-03-01 03:00:00                0.0                0.0   \n",
       "4           4  2019-03-01 04:00:00                0.0                0.0   \n",
       "\n",
       "   Total Power (avg)  Total Power (samp)  Total Power (trimmed)  \\\n",
       "0                0.0                 0.0                    0.0   \n",
       "1                0.0                 0.0                    0.0   \n",
       "2                0.0                 0.0                    0.0   \n",
       "3                0.0                 0.0                    0.0   \n",
       "4                0.0                 0.0                    0.0   \n",
       "\n",
       "   HourlyDewPointTemperature  HourlyDryBulbTemperature HourlyPrecipitation  \\\n",
       "0                        9.0                      17.0                0.00   \n",
       "1                        9.0                      17.0                0.00   \n",
       "2                        9.0                      17.0                0.00   \n",
       "3                       10.0                      19.0                0.00   \n",
       "4                        8.0                      16.0                0.00   \n",
       "\n",
       "   ...   FG   FZ   GS   HZ   MI   PL   RA   SN   TS  VCTS  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('merged_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting columns of interest to us.\n",
    "filtered_cols = [\n",
    "    'DATE',\n",
    "    'Total Power (trimmed)',\n",
    "    'HourlyDryBulbTemperature',\n",
    "    'HourlyWetBulbTemperature'\n",
    "]\n",
    "\n",
    "## Making a new dataframe only with these columns of interest.\n",
    "hourly = df[filtered_cols]\n",
    "#hourly['DATE'] = hourly['DATE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wade\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "hourly[\"DATE\"] = hourly.apply(lambda x: pd.Timestamp(x[\"DATE\"]), axis=1)\n",
    "\n",
    "colList = hourly.copy().columns[:-1] \n",
    "\n",
    "groupby = hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add h-1 to h-n and h+1 to h+24, current time, DoW, and month\n",
    "# max power, avg power?, dry bulb temp, humidity\n",
    "# Row: h0 power, h0 weather, h- power, h- weather, h+ weather, (h+ power) together\n",
    "# features should be built on information from the last several hours\n",
    "\n",
    "def windowData(df, npast=0, nfuture=0, colpast=[], colfuture=[]):\n",
    "    # init return variable\n",
    "    outdf = df.copy()\n",
    "    \n",
    "    # add past windows\n",
    "    kept_past = df[colpast]  # elements used past windows\n",
    "    for i in range(1,npast+1):\n",
    "        temp = kept_past.shift(i)\n",
    "        temp.columns = [f\"{c}-{i}hr\" for c in kept_past.columns]\n",
    "        outdf = pd.concat([outdf,temp],axis=1)\n",
    "        \n",
    "    # add future windows\n",
    "    kept_future = df[colfuture]  # elements used future windows\n",
    "    for i in range(1,nfuture+1):\n",
    "        temp = kept_future.shift(-i)\n",
    "        temp.columns = [f\"{c}+{i}hr\" for c in kept_future.columns]\n",
    "        outdf = pd.concat([outdf,temp],axis=1)\n",
    "    \n",
    "    return outdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_features = ['Total Power (trimmed)', 'HourlyDryBulbTemperature', 'HourlyWetBulbTemperature']\n",
    "future_features = ['HourlyDryBulbTemperature', 'HourlyWetBulbTemperature']\n",
    "\n",
    "hourlyWindowed = windowData(hourly, npast=12, nfuture=24, colpast=past_features, colfuture=future_features)\n",
    "\n",
    "#hourlyWindowed = hourlyWindowed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding TS features (later)\n",
    "\n",
    "#Adding day of week, day of year, time of day measures\n",
    "## ** I think these are categorical and should be represented as dummy variables **\n",
    "## implemented with cyclicality represented by sin and cos\n",
    "months = hourly.apply(lambda x: x[\"DATE\"].month, axis=1)\n",
    "hourlyWindowed['month_sin'] = np.sin((months-1)*(2.*np.pi/12))\n",
    "hourlyWindowed['month_cos'] = np.cos((months-1)*(2.*np.pi/12))\n",
    "\n",
    "dow = hourly.apply(lambda x: x[\"DATE\"].dayofweek, axis=1)\n",
    "hourlyWindowed['DoW_sin'] = np.sin(dow*(2.*np.pi/7))\n",
    "hourlyWindowed['DoW_cos'] = np.cos(dow*(2.*np.pi/7))\n",
    "    \n",
    "hr = hourly.apply(lambda x: x[\"DATE\"].hour, axis=1)\n",
    "hourlyWindowed['Hour_sin'] = np.sin(hr*(2.*np.pi/24))\n",
    "hourlyWindowed['Hour_cos'] = np.cos(hr*(2.*np.pi/24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build train and test (2 sets, one time-seperated, one random)\n",
    "# Cutoff date between train and test data (CV train set)\n",
    "# also worth trying random sampling\n",
    "\n",
    "#response_col = 'Total Power (trimmed)'\n",
    "\n",
    "#def split(df, perc_split=0.8, response=response_col, shuffled=False):\n",
    "#    # Shuffled determines if split should be random (True) or sequential (False)\n",
    "#    \n",
    "#    X = df.drop(columns = ['DATE', f\"{response}\"])  # predictors are all features except response and date\n",
    "#    Y = df[response_col]  # response is as specified in argument\n",
    "#    \n",
    "#    return train_test_split(X, Y, train_size = perc_split, random_state=12345, shuffle=shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genXY(X, target_var, maxoffset=1):\n",
    "    '''\n",
    "    Generate X and Y data to be used in run model. X should be untrimmed (include NaNs).\n",
    "    \n",
    "    Will return tuple contianing trimmed X and list of Y vectors with offset ranging from 1 to maxoffset.\n",
    "    '''\n",
    "    df = X.copy()\n",
    "    Y = []\n",
    "    \n",
    "    for l in range(1,maxoffset+1):\n",
    "        df[f\"offset_{l}\"] = df[target_var].shift(-l)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(columns=['DATE'])\n",
    "    \n",
    "    for l in range(1,maxoffset+1):\n",
    "        Y.append(df[f\"offset_{l}\"])\n",
    "        df.drop(columns=[f\"offset_{l}\"], inplace=True)\n",
    "    \n",
    "    return (df, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Ys = genXY(hourlyWindowed, 'Total Power (trimmed)', maxoffset=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make and run model\n",
    "def runModel(X, Y, model, verbose=False):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=12345, shuffle=False)  # create train and test sets\n",
    "\n",
    "    model.fit(X_train, Y_train)  # fit model\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    rsq = model.score(X_test, Y_test)\n",
    "    rmse = math.sqrt(metrics.mean_squared_error(Y_test, model.predict(X_test)))\n",
    "    mae = metrics.mean_absolute_error(Y_test, model.predict(X_test))\n",
    "    \n",
    "    # Display if selected in arguments\n",
    "    if verbose:\n",
    "        print(\"R Squared Score: {:.4f}\".format(rsq))\n",
    "        print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "        print(\"Mean Absolute Error: {:.2f}\".format(mae))\n",
    "\n",
    "    #importance = pd.DataFrame({'col_name': rf.feature_importances_}, index=X.columns).sort_values(by='col_name', ascending=False)\n",
    "    #importance['col_name'] = 100*importance['col_name']\n",
    "    #print(importance[:10])\n",
    "    \n",
    "    return model, mae, rmse, rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared Score: 0.9665\n",
      "Root Mean Squared Error: 354.90\n",
      "Mean Absolute Error: 197.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestRegressor(),\n",
       " 197.3845032682265,\n",
       " 354.9027453158792,\n",
       " 0.9665024850309276)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runModel(X=X, Y=Ys[0], model= RandomForestRegressor(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltErrors(errorDict,model=\"\"):\n",
    "    plt.plot(errorDict['ndays'], errorDict['MAE'])\n",
    "    plt.plot(errorDict['ndays'], errorDict['RMSE'])\n",
    "    \n",
    "    plt.legend(['MAE', 'RMSE'])\n",
    "    plt.xlabel('Hours in the future')\n",
    "    plt.ylabel('Model Error')\n",
    "    plt.title(f'Future Prediction Error {model}')\n",
    "    plt.ylim(ymin=0, ymax =3000)\n",
    "    xint = range(min(errorDict['ndays']), math.ceil(max(errorDict['ndays']))+1)\n",
    "    plt.xticks(xint)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testErrors(X, Ys, model):\n",
    "    errors = {'ndays':list(range(1,len(Ys)+1)),'MAE':[], 'RMSE':[], 'RSQ':[]}\n",
    "    for Y in Ys:\n",
    "        _, mae, rmse, rsq = runModel(X, Y, model)\n",
    "        errors['MAE'].append(mae)\n",
    "        errors['RMSE'].append(rmse)\n",
    "        errors['RSQ'].append(rsq)\n",
    "        \n",
    "        \n",
    "    pltErrors(errors, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(0.) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-8459e08bdf39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestErrors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-176-3437c0b1b547>\u001b[0m in \u001b[0;36mtestErrors\u001b[1;34m(X, Ys, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'ndays'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MAE'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RSQ'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MAE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-171-0015e213f03f>\u001b[0m in \u001b[0;36mrunModel\u001b[1;34m(X, Y, model, verbose)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrunModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# create train and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 203\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(0.) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "testErrors(X=X, Ys=Ys[0], model= RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Questions:\n",
    "## Can we improve by creating dummy variables for time of day?\n",
    "## Then incrimenting an hour of day input parameter by one for each prediction?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
